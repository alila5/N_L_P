{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим предобработку данных с Твиттера, чтобы отчищенный данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания.\n",
    "Для работы объединим train_df и test_df.\n",
    "\n",
    "Задания:\n",
    "\n",
    "1) Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n",
    "\n",
    "2) Изменим регистр твитов на нижний с помощью .lower().\n",
    "\n",
    "3) Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова).\n",
    "\n",
    "4) Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
    "\n",
    "5) Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
    "\n",
    "6) Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
    "\n",
    "7) Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
    "\n",
    "8) Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'.\n",
    "\n",
    "9) Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1]).\n",
    "\n",
    "10) Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'.\n",
    "\n",
    "11) Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов.\n",
    "\n",
    "12) Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга.\n",
    "\n",
    "13) Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации.\n",
    "\n",
    "14) Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}\n",
    "\n",
    "\n",
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_tweets.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_tweets.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...\n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3    0.0                                bihday your majesty\n",
       "3   4    0.0  #model   i love u take with u all the time in ...\n",
       "4   5    0.0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = train_df.append(test_df, ignore_index = True, sort = False)\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_df = train_df.copy()\n",
    "# for i in range (0,100):\n",
    "#     combine_df = combine_df.append(train_df, ignore_index = True, sort = False)\n",
    "# combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      49159 non-null  int64  \n",
      " 1   label   31962 non-null  float64\n",
      " 2   tweet   49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def reg_sub(x, pattern='@[\\w]*', sub_to=''):\n",
    "    regs = re.findall(pattern, x)\n",
    "    for reg in regs:\n",
    "        x = re.sub(reg, sub_to, x).strip()\n",
    "    return x\n",
    "\n",
    "x = np.vectorize(reg_sub)\n",
    "\n",
    "combine_df['clean_tweet'] = x(combine_df['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вариант 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОЧЕМУ НЕ РАБОТАЕТ ?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63c0a4ae108478fba91a716155e010d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "with Pool(6) as p:\n",
    "    lemmas = list(tqdm(p.imap(reg_sub, combine_df['tweet']), total=len(combine_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 95.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "combine_df['clean_tweet1']=combine_df['tweet'].apply(reg_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(combine_df['clean_tweet'], combine_df['clean_tweet1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when a father is dysfunctional and is so selfi...   \n",
       "1  thanks for #lyft credit i can't use cause they...   \n",
       "2                                bihday your majesty   \n",
       "3  #model   i love u take with u all the time in ...   \n",
       "4             factsguide: society now    #motivation   \n",
       "\n",
       "                                        clean_tweet1  \n",
       "0  when a father is dysfunctional and is so selfi...  \n",
       "1  thanks for #lyft credit i can't use cause they...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Изменим регистр твитов на нижний с помощью .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clean_tweet'] = combine_df['clean_tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clean_tweet1'] = combine_df['clean_tweet1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(combine_df['clean_tweet'], combine_df['clean_tweet1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def reduce(function, iterable, initializer=None):\n",
    "    it = iter(iterable)\n",
    "    if initializer is None:\n",
    "        try:\n",
    "            initializer = next(it)\n",
    "        except StopIteration:\n",
    "            raise TypeError('reduce() of empty sequence with no initial value')\n",
    "    accum_value = initializer\n",
    "    for x in it:\n",
    "        accum_value = function(accum_value, x)\n",
    "    return accum_value\n",
    "\n",
    "def replace_from_dict(s, dict, prefix = ''):\n",
    "    return reduce(lambda x, y: x.replace(y, prefix+dict[y]), dict, s)\n",
    "\n",
    "x = np.vectorize(replace_from_dict)\n",
    "\n",
    "combine_df['clean_tweet'] = x(combine_df['clean_tweet'], apostrophe_dict)\n",
    "combine_df['clean_tweet'] = combine_df['clean_tweet'].apply(lambda x:' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def func(txt, dict, replacer=None):\n",
    "    if replacer is  None:\n",
    "        return  ' '.join([dict[re.sub(r'[\\\\.,\"]', \"\", w)] if re.sub(r'[\\\\.,\"]', \"\", w) in list(dict.keys()) \n",
    "                      else  w for w in txt.split()])\n",
    "    #re.sub(r'[\\.]', \"\", w)\n",
    "    else: \n",
    "        return  ' '.join([replacer if w in list(dict.keys())  \n",
    "                      else w for w in txt.split()])\n",
    "\n",
    "combine_df['clean_tweet3'] = combine_df['clean_tweet1'].apply(lambda x:func(x, apostrophe_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(combine_df['clean_tweet'], combine_df['clean_tweet3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet1</th>\n",
       "      <th>clean_tweet3</th>\n",
       "      <th>bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user my wife whom i adore had to miss your po...</td>\n",
       "      <td>my wife whom i adore had to miss your poland s...</td>\n",
       "      <td>my wife whom i adore had to miss your poland s...</td>\n",
       "      <td>my wife whom i adore had to miss your poland s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>this really takes the piss. i'm so angry. just...</td>\n",
       "      <td>this really takes the piss. I am so angry. jus...</td>\n",
       "      <td>this really takes the piss. i'm so angry. just...</td>\n",
       "      <td>this really takes the piss. I am so angry. jus...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"there's a reason why two people stay together...</td>\n",
       "      <td>\"there has / there is a reason why two people ...</td>\n",
       "      <td>\"there's a reason why two people stay together...</td>\n",
       "      <td>there has / there is a reason why two people s...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>if you hold open a door for a woman because sh...</td>\n",
       "      <td>if you hold open a door for a woman because sh...</td>\n",
       "      <td>if you hold open a door for a woman because sh...</td>\n",
       "      <td>if you hold open a door for a woman because sh...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#itako#alone#it's fine.  a little.</td>\n",
       "      <td>#itako#alone#it has / it is fine. a little.</td>\n",
       "      <td>#itako#alone#it's fine.  a little.</td>\n",
       "      <td>#itako#alone#it's fine. a little.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48274</th>\n",
       "      <td>48275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what i did today , for himself ,will make a fu...</td>\n",
       "      <td>what i did today , for himself ,will make a fu...</td>\n",
       "      <td>what i did today , for himself ,will make a fu...</td>\n",
       "      <td>what i did today , for himself ,will make a fu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48548</th>\n",
       "      <td>48549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user you're so fucking gullible. of course th...</td>\n",
       "      <td>you are so fucking gullible. of course they di...</td>\n",
       "      <td>you're so fucking gullible. of course they did...</td>\n",
       "      <td>you are so fucking gullible. of course they di...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48830</th>\n",
       "      <td>48831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user @user the line \"don't be an idiot like m...</td>\n",
       "      <td>the line \"do not be an idiot like most human m...</td>\n",
       "      <td>the line \"don't be an idiot like most human ma...</td>\n",
       "      <td>the line do not be an idiot like most human ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49057</th>\n",
       "      <td>49058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user \"we're all in this together\" sounds swel...</td>\n",
       "      <td>\"we are all in this together\" sounds swell unt...</td>\n",
       "      <td>\"we're all in this together\" sounds swell unti...</td>\n",
       "      <td>we are all in this together\" sounds swell unti...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49125</th>\n",
       "      <td>49126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user @user i'd be ashamed of my state if i to...</td>\n",
       "      <td>I had / I would be ashamed of my state if i to...</td>\n",
       "      <td>i'd be ashamed of my state if i took any respo...</td>\n",
       "      <td>I had / I would be ashamed of my state if i to...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "64        65    0.0  @user my wife whom i adore had to miss your po...   \n",
       "209      210    0.0  this really takes the piss. i'm so angry. just...   \n",
       "225      226    0.0  \"there's a reason why two people stay together...   \n",
       "232      233    1.0  if you hold open a door for a woman because sh...   \n",
       "258      259    0.0                #itako#alone#it's fine.  a little.    \n",
       "...      ...    ...                                                ...   \n",
       "48274  48275    NaN  what i did today , for himself ,will make a fu...   \n",
       "48548  48549    NaN  @user you're so fucking gullible. of course th...   \n",
       "48830  48831    NaN  @user @user the line \"don't be an idiot like m...   \n",
       "49057  49058    NaN  @user \"we're all in this together\" sounds swel...   \n",
       "49125  49126    NaN  @user @user i'd be ashamed of my state if i to...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "64     my wife whom i adore had to miss your poland s...   \n",
       "209    this really takes the piss. I am so angry. jus...   \n",
       "225    \"there has / there is a reason why two people ...   \n",
       "232    if you hold open a door for a woman because sh...   \n",
       "258          #itako#alone#it has / it is fine. a little.   \n",
       "...                                                  ...   \n",
       "48274  what i did today , for himself ,will make a fu...   \n",
       "48548  you are so fucking gullible. of course they di...   \n",
       "48830  the line \"do not be an idiot like most human m...   \n",
       "49057  \"we are all in this together\" sounds swell unt...   \n",
       "49125  I had / I would be ashamed of my state if i to...   \n",
       "\n",
       "                                            clean_tweet1  \\\n",
       "64     my wife whom i adore had to miss your poland s...   \n",
       "209    this really takes the piss. i'm so angry. just...   \n",
       "225    \"there's a reason why two people stay together...   \n",
       "232    if you hold open a door for a woman because sh...   \n",
       "258                  #itako#alone#it's fine.  a little.    \n",
       "...                                                  ...   \n",
       "48274  what i did today , for himself ,will make a fu...   \n",
       "48548  you're so fucking gullible. of course they did...   \n",
       "48830  the line \"don't be an idiot like most human ma...   \n",
       "49057  \"we're all in this together\" sounds swell unti...   \n",
       "49125  i'd be ashamed of my state if i took any respo...   \n",
       "\n",
       "                                            clean_tweet3  bool  \n",
       "64     my wife whom i adore had to miss your poland s...  True  \n",
       "209    this really takes the piss. I am so angry. jus...  True  \n",
       "225    there has / there is a reason why two people s...  True  \n",
       "232    if you hold open a door for a woman because sh...  True  \n",
       "258                    #itako#alone#it's fine. a little.  True  \n",
       "...                                                  ...   ...  \n",
       "48274  what i did today , for himself ,will make a fu...  True  \n",
       "48548  you are so fucking gullible. of course they di...  True  \n",
       "48830  the line do not be an idiot like most human ma...  True  \n",
       "49057  we are all in this together\" sounds swell unti...  True  \n",
       "49125  I had / I would be ashamed of my state if i to...  True  \n",
       "\n",
       "[411 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['bool'] = combine_df['clean_tweet']!=combine_df['clean_tweet3']\n",
    "df = combine_df[combine_df['bool'] == True]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[\\\\.,\"]', \"\", '\"..\\\\\\do\\.,\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@user my wife whom i adore had to miss your poland show because she had surgery. her name is bridget &amp; she's my everything.  \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet'][64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wife whom i adore had to miss your poland show because she had surgery. her name is bridget &amp; she has / he is my everything.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet'][64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wife whom i adore had to miss your poland show because she had surgery. her name is bridget &amp; she has / she is my everything.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet3'][64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@user @user the line \"don\\'t be an idiot like most human males\". same line about females would cause an uproar. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet'][48830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the line \"do not be an idiot like most human males\". same line about females would cause an uproar.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet'][48830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the line do not be an idiot like most human males\". same line about females would cause an uproar.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet3'][48830]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = np.vectorize(replace_from_dict)\n",
    "combine_df['clean_tweet'] = x(combine_df['clean_tweet'], short_word_dict)\n",
    "combine_df['clean_tweet'] = combine_df['clean_tweet'].apply(lambda x:' '.join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['clean_tweet4'] = combine_df['clean_tweet3'].apply(lambda x:func(x, short_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(combine_df['clean_tweet3'], combine_df['clean_tweet4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet1</th>\n",
       "      <th>clean_tweet3</th>\n",
       "      <th>bool</th>\n",
       "      <th>clean_tweet4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>there are some truly sick ppl out there.</td>\n",
       "      <td>thearee aaree some tareyouly sI seek people oy...</td>\n",
       "      <td>there are some truly sick ppl out there.</td>\n",
       "      <td>there are some truly sick ppl out there.</td>\n",
       "      <td>True</td>\n",
       "      <td>there are some truly sick people out there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48946</th>\n",
       "      <td>48947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it's amazing how a bit of recognition for ur h...</td>\n",
       "      <td>it has / it is amazingarein how a bit of areec...</td>\n",
       "      <td>it's amazing how a bit of recognition for ur h...</td>\n",
       "      <td>it has / it is amazing how a bit of recognitio...</td>\n",
       "      <td>True</td>\n",
       "      <td>it has / it is amazing how a bit of recognitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48981</th>\n",
       "      <td>48982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user i will never understand why people in c...</td>\n",
       "      <td>i will neveare youndearestand why people in co...</td>\n",
       "      <td>i will never understand why people in college ...</td>\n",
       "      <td>i will never understand why people in college ...</td>\n",
       "      <td>True</td>\n",
       "      <td>i will never understand why people in college ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49133</th>\n",
       "      <td>49134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49134</th>\n",
       "      <td>49135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in life u will grow to learn some pple will wo...</td>\n",
       "      <td>in life you will gareinareow to leaaren some p...</td>\n",
       "      <td>in life u will grow to learn some pple will wo...</td>\n",
       "      <td>in life u will grow to learn some pple will wo...</td>\n",
       "      <td>True</td>\n",
       "      <td>in life you will grow to learn some pple will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49144</th>\n",
       "      <td>49145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>when ur the joke ur defensive towards everythi...</td>\n",
       "      <td>when youare the joke youare defensive towaared...</td>\n",
       "      <td>when ur the joke ur defensive towards everythi...</td>\n",
       "      <td>when ur the joke ur defensive towards everythi...</td>\n",
       "      <td>True</td>\n",
       "      <td>when you are the joke you are defensive toward...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "46        47    0.0  #model   i love u take with u all the time in ...   \n",
       "96        97    0.0  #model   i love u take with u all the time in ...   \n",
       "100      101    0.0        there are some truly sick ppl out there.      \n",
       "117      118    0.0  #model   i love u take with u all the time in ...   \n",
       "...      ...    ...                                                ...   \n",
       "48946  48947    NaN  it's amazing how a bit of recognition for ur h...   \n",
       "48981  48982    NaN   @user i will never understand why people in c...   \n",
       "49133  49134    NaN  #model   i love u take with u all the time in ...   \n",
       "49134  49135    NaN  in life u will grow to learn some pple will wo...   \n",
       "49144  49145    NaN  when ur the joke ur defensive towards everythi...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "3      #model i love you take with you all the time i...   \n",
       "46     #model i love you take with you all the time i...   \n",
       "96     #model i love you take with you all the time i...   \n",
       "100    thearee aaree some tareyouly sI seek people oy...   \n",
       "117    #model i love you take with you all the time i...   \n",
       "...                                                  ...   \n",
       "48946  it has / it is amazingarein how a bit of areec...   \n",
       "48981  i will neveare youndearestand why people in co...   \n",
       "49133  #model i love you take with you all the time i...   \n",
       "49134  in life you will gareinareow to leaaren some p...   \n",
       "49144  when youare the joke youare defensive towaared...   \n",
       "\n",
       "                                            clean_tweet1  \\\n",
       "3      #model   i love u take with u all the time in ...   \n",
       "46     #model   i love u take with u all the time in ...   \n",
       "96     #model   i love u take with u all the time in ...   \n",
       "100          there are some truly sick ppl out there.      \n",
       "117    #model   i love u take with u all the time in ...   \n",
       "...                                                  ...   \n",
       "48946  it's amazing how a bit of recognition for ur h...   \n",
       "48981  i will never understand why people in college ...   \n",
       "49133  #model   i love u take with u all the time in ...   \n",
       "49134  in life u will grow to learn some pple will wo...   \n",
       "49144  when ur the joke ur defensive towards everythi...   \n",
       "\n",
       "                                            clean_tweet3  bool  \\\n",
       "3      #model i love u take with u all the time in ur...  True   \n",
       "46     #model i love u take with u all the time in ur...  True   \n",
       "96     #model i love u take with u all the time in ur...  True   \n",
       "100             there are some truly sick ppl out there.  True   \n",
       "117    #model i love u take with u all the time in ur...  True   \n",
       "...                                                  ...   ...   \n",
       "48946  it has / it is amazing how a bit of recognitio...  True   \n",
       "48981  i will never understand why people in college ...  True   \n",
       "49133  #model i love u take with u all the time in ur...  True   \n",
       "49134  in life u will grow to learn some pple will wo...  True   \n",
       "49144  when ur the joke ur defensive towards everythi...  True   \n",
       "\n",
       "                                            clean_tweet4  \n",
       "3      #model i love you take with you all the time i...  \n",
       "46     #model i love you take with you all the time i...  \n",
       "96     #model i love you take with you all the time i...  \n",
       "100          there are some truly sick people out there.  \n",
       "117    #model i love you take with you all the time i...  \n",
       "...                                                  ...  \n",
       "48946  it has / it is amazing how a bit of recognitio...  \n",
       "48981  i will never understand why people in college ...  \n",
       "49133  #model i love you take with you all the time i...  \n",
       "49134  in life you will grow to learn some pple will ...  \n",
       "49144  when you are the joke you are defensive toward...  \n",
       "\n",
       "[1989 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['bool'] = combine_df['clean_tweet3']!=combine_df['clean_tweet4']\n",
    "df = combine_df[combine_df['bool'] == True]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#model i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91 ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet3'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#model i love you take with you all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91 ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet4'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 723 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['clean_tweet5'] = combine_df['clean_tweet4'].apply(lambda x:func(x, emoticon_dict, replacer= ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet1</th>\n",
       "      <th>clean_tweet3</th>\n",
       "      <th>bool</th>\n",
       "      <th>clean_tweet4</th>\n",
       "      <th>clean_tweet5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you've really hu my feelings :(</td>\n",
       "      <td>yoyou have areeally hyou my feelingareins :(</td>\n",
       "      <td>you've really hu my feelings :(</td>\n",
       "      <td>you have really hu my feelings :(</td>\n",
       "      <td>True</td>\n",
       "      <td>you have really hu my feelings :(</td>\n",
       "      <td>you have really hu my feelings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>yeah! new buttons in the mail for me ð  the...</td>\n",
       "      <td>yeah! new byouttons in the mail foare me ð ...</td>\n",
       "      <td>yeah! new buttons in the mail for me ð  the...</td>\n",
       "      <td>yeah! new buttons in the mail for me ð they...</td>\n",
       "      <td>True</td>\n",
       "      <td>yeah! new buttons in the mail for me ð they...</td>\n",
       "      <td>yeah! new buttons in the mail for me ð they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when you know yall 2 aint going know where :) ...</td>\n",
       "      <td>when yoyou know yall 2 aint gareinoingarein kn...</td>\n",
       "      <td>when you know yall 2 aint going know where :) ...</td>\n",
       "      <td>when you know yall 2 aint going know where :) ...</td>\n",
       "      <td>True</td>\n",
       "      <td>when you know yall 2 aint going know where :) ...</td>\n",
       "      <td>when you know yall 2 aint going know where   #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my hea is with #orlando right now. i truly can...</td>\n",
       "      <td>my hea is with #oarelando areigareinht now. i ...</td>\n",
       "      <td>my hea is with #orlando right now. i truly can...</td>\n",
       "      <td>my hea is with #orlando right now. i truly can...</td>\n",
       "      <td>True</td>\n",
       "      <td>my hea is with #orlando right now. i truly can...</td>\n",
       "      <td>my hea is with #orlando right now. i truly can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>it seems like the only place with action here ...</td>\n",
       "      <td>it seems like the only place with action heare...</td>\n",
       "      <td>it seems like the only place with action here ...</td>\n",
       "      <td>it seems like the only place with action here ...</td>\n",
       "      <td>True</td>\n",
       "      <td>it seems like the only place with action here ...</td>\n",
       "      <td>it seems like the only place with action here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>48837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iâm glad i finally got to see you again :) #...</td>\n",
       "      <td>iâm gareinlad i finally gareinot to see yoyo...</td>\n",
       "      <td>iâm glad i finally got to see you again :) #...</td>\n",
       "      <td>iâm glad i finally got to see you again :) #...</td>\n",
       "      <td>True</td>\n",
       "      <td>iâm glad i finally got to see you again :) #...</td>\n",
       "      <td>iâm glad i finally got to see you again   #f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48956</th>\n",
       "      <td>48957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@user hill 10km in 1:14 up mountains, hills wh...</td>\n",
       "      <td>hill 10km in 1:14 youp moyountains, hills whea...</td>\n",
       "      <td>hill 10km in 1:14 up mountains, hills where un...</td>\n",
       "      <td>hill 10km in 1:14 up mountains, hills where un...</td>\n",
       "      <td>True</td>\n",
       "      <td>hill 10km in 1:14 up mountains, hills where un...</td>\n",
       "      <td>hill 10km in 1:14 up mountains, hills where un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49003</th>\n",
       "      <td>49004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>something to brighten your day... or possibly ...</td>\n",
       "      <td>somethingarein to bareigareinhten yoyouare day...</td>\n",
       "      <td>something to brighten your day... or possibly ...</td>\n",
       "      <td>something to brighten your day... or possibly ...</td>\n",
       "      <td>True</td>\n",
       "      <td>something to brighten your day... or possibly ...</td>\n",
       "      <td>something to brighten your day... or possibly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49040</th>\n",
       "      <td>49041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#100daysofpositivechange ... :) what do you th...</td>\n",
       "      <td>#100daysofpositivechangareine ... :) what do y...</td>\n",
       "      <td>#100daysofpositivechange ... :) what do you th...</td>\n",
       "      <td>#100daysofpositivechange ... :) what do you th...</td>\n",
       "      <td>True</td>\n",
       "      <td>#100daysofpositivechange ... :) what do you th...</td>\n",
       "      <td>#100daysofpositivechange ...   what do you thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49131</th>\n",
       "      <td>49132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tomorrow is gonna be a big day! we are going t...</td>\n",
       "      <td>tomoareareow is gareinonna be a bigarein day! ...</td>\n",
       "      <td>tomorrow is gonna be a big day! we are going t...</td>\n",
       "      <td>tomorrow is gonna be a big day! we are going t...</td>\n",
       "      <td>True</td>\n",
       "      <td>tomorrow is gonna be a big day! we are going t...</td>\n",
       "      <td>tomorrow is gonna be a big day! we are going t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>652 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "63        64    0.0                  you've really hu my feelings :(     \n",
       "128      129    0.0  yeah! new buttons in the mail for me ð  the...   \n",
       "150      151    0.0  when you know yall 2 aint going know where :) ...   \n",
       "199      200    0.0  my hea is with #orlando right now. i truly can...   \n",
       "201      202    0.0  it seems like the only place with action here ...   \n",
       "...      ...    ...                                                ...   \n",
       "48836  48837    NaN  iâm glad i finally got to see you again :) #...   \n",
       "48956  48957    NaN  @user hill 10km in 1:14 up mountains, hills wh...   \n",
       "49003  49004    NaN  something to brighten your day... or possibly ...   \n",
       "49040  49041    NaN  #100daysofpositivechange ... :) what do you th...   \n",
       "49131  49132    NaN  tomorrow is gonna be a big day! we are going t...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "63          yoyou have areeally hyou my feelingareins :(   \n",
       "128    yeah! new byouttons in the mail foare me ð ...   \n",
       "150    when yoyou know yall 2 aint gareinoingarein kn...   \n",
       "199    my hea is with #oarelando areigareinht now. i ...   \n",
       "201    it seems like the only place with action heare...   \n",
       "...                                                  ...   \n",
       "48836  iâm gareinlad i finally gareinot to see yoyo...   \n",
       "48956  hill 10km in 1:14 youp moyountains, hills whea...   \n",
       "49003  somethingarein to bareigareinhten yoyouare day...   \n",
       "49040  #100daysofpositivechangareine ... :) what do y...   \n",
       "49131  tomoareareow is gareinonna be a bigarein day! ...   \n",
       "\n",
       "                                            clean_tweet1  \\\n",
       "63                     you've really hu my feelings :(     \n",
       "128    yeah! new buttons in the mail for me ð  the...   \n",
       "150    when you know yall 2 aint going know where :) ...   \n",
       "199    my hea is with #orlando right now. i truly can...   \n",
       "201    it seems like the only place with action here ...   \n",
       "...                                                  ...   \n",
       "48836  iâm glad i finally got to see you again :) #...   \n",
       "48956  hill 10km in 1:14 up mountains, hills where un...   \n",
       "49003  something to brighten your day... or possibly ...   \n",
       "49040  #100daysofpositivechange ... :) what do you th...   \n",
       "49131  tomorrow is gonna be a big day! we are going t...   \n",
       "\n",
       "                                            clean_tweet3  bool  \\\n",
       "63                     you have really hu my feelings :(  True   \n",
       "128    yeah! new buttons in the mail for me ð they...  True   \n",
       "150    when you know yall 2 aint going know where :) ...  True   \n",
       "199    my hea is with #orlando right now. i truly can...  True   \n",
       "201    it seems like the only place with action here ...  True   \n",
       "...                                                  ...   ...   \n",
       "48836  iâm glad i finally got to see you again :) #...  True   \n",
       "48956  hill 10km in 1:14 up mountains, hills where un...  True   \n",
       "49003  something to brighten your day... or possibly ...  True   \n",
       "49040  #100daysofpositivechange ... :) what do you th...  True   \n",
       "49131  tomorrow is gonna be a big day! we are going t...  True   \n",
       "\n",
       "                                            clean_tweet4  \\\n",
       "63                     you have really hu my feelings :(   \n",
       "128    yeah! new buttons in the mail for me ð they...   \n",
       "150    when you know yall 2 aint going know where :) ...   \n",
       "199    my hea is with #orlando right now. i truly can...   \n",
       "201    it seems like the only place with action here ...   \n",
       "...                                                  ...   \n",
       "48836  iâm glad i finally got to see you again :) #...   \n",
       "48956  hill 10km in 1:14 up mountains, hills where un...   \n",
       "49003  something to brighten your day... or possibly ...   \n",
       "49040  #100daysofpositivechange ... :) what do you th...   \n",
       "49131  tomorrow is gonna be a big day! we are going t...   \n",
       "\n",
       "                                            clean_tweet5  \n",
       "63                      you have really hu my feelings    \n",
       "128    yeah! new buttons in the mail for me ð they...  \n",
       "150    when you know yall 2 aint going know where   #...  \n",
       "199    my hea is with #orlando right now. i truly can...  \n",
       "201    it seems like the only place with action here ...  \n",
       "...                                                  ...  \n",
       "48836  iâm glad i finally got to see you again   #f...  \n",
       "48956  hill 10km in 1:14 up mountains, hills where un...  \n",
       "49003  something to brighten your day... or possibly ...  \n",
       "49040  #100daysofpositivechange ...   what do you thi...  \n",
       "49131  tomorrow is gonna be a big day! we are going t...  \n",
       "\n",
       "[652 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['bool'] = combine_df['clean_tweet4']!=combine_df['clean_tweet5']\n",
    "df = combine_df[combine_df['bool'] == True]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you've really hu my feelings :(  \""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['tweet'][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have really hu my feelings :('"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet4'][63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you have really hu my feelings  '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet5'][63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 247 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['clean_tweet6'] = combine_df['clean_tweet5'].str.replace(r'[^\\w\\s]+', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 306 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['clean_tweet7'] = combine_df['clean_tweet6'].str.replace(r'[^a-zA-Z0-9]', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['clean_tweet8'] = combine_df['clean_tweet7'].str.replace(r'[^a-zA-Z]', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def delete_words_by_len(txt, length = 1):\n",
    "    return ' '.join([w for w in txt.split() if len(w)>length])\n",
    "\n",
    "combine_df['clean_tweet9'] = combine_df['clean_tweet8'].apply(lambda x:\n",
    "                                                              delete_words_by_len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet1</th>\n",
       "      <th>clean_tweet3</th>\n",
       "      <th>bool</th>\n",
       "      <th>clean_tweet4</th>\n",
       "      <th>clean_tweet5</th>\n",
       "      <th>clean_tweet6</th>\n",
       "      <th>clean_tweet7</th>\n",
       "      <th>clean_tweet8</th>\n",
       "      <th>clean_tweet9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a fatheare is dysfyounctional and is so s...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>True</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when a father is dysfunctional and is so selfi...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks foare #lyft careedit i cannot youse cay...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause they...</td>\n",
       "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
       "      <td>True</td>\n",
       "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
       "      <td>thanks for #lyft credit i cannot use cause the...</td>\n",
       "      <td>thanks for  lyft credit i cannot use cause the...</td>\n",
       "      <td>thanks for  lyft credit i cannot use cause the...</td>\n",
       "      <td>thanks for  lyft credit i cannot use cause the...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model i love u take with u all the time in ur...</td>\n",
       "      <td>True</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>#model i love you take with you all the time i...</td>\n",
       "      <td>model i love you take with you all the time i...</td>\n",
       "      <td>model i love you take with you all the time i...</td>\n",
       "      <td>model i love you take with you all the time i...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsgareinyouide: society now #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>True</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>factsguide: society now #motivation</td>\n",
       "      <td>factsguide  society now  motivation</td>\n",
       "      <td>factsguide  society now  motivation</td>\n",
       "      <td>factsguide  society now  motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] hyougareine fan faaree and bigarein talk...</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>True</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>2 2  huge fan fare and big talking before the...</td>\n",
       "      <td>2 2  huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before they leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thoyougareinht factoarey: left-areigareinht po...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>True</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory  left right polarisation   tru...</td>\n",
       "      <td>thought factory  left right polarisation   tru...</td>\n",
       "      <td>thought factory  left right polarisation   tru...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feelingarein like a mearemaid ð #haiareflip...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>True</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like a mermaid ð   hairflip  neverread...</td>\n",
       "      <td>feeling like a mermaid     hairflip  neverread...</td>\n",
       "      <td>feeling like a mermaid     hairflip  neverread...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillaarey #campaigareinned today in #ohio((oh...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>True</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary  campaigned today in  ohio omg   amp ...</td>\n",
       "      <td>hillary  campaigned today in  ohio omg   amp ...</td>\n",
       "      <td>hillary  campaigned today in  ohio omg   amp ...</td>\n",
       "      <td>hillary campaigned today in ohio omg amp used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at woarek confeareence: areigareinht mi...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>True</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy  at work conference  right mindset leads...</td>\n",
       "      <td>happy  at work conference  right mindset leads...</td>\n",
       "      <td>happy  at work conference  right mindset leads...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my songarein \"so gareinlad\" fareee download! #...</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>my song \"so glad\" free download! #shoegaze #ne...</td>\n",
       "      <td>True</td>\n",
       "      <td>my song \"so glad\" free download! #shoegaze #ne...</td>\n",
       "      <td>my song \"so glad\" free download! #shoegaze #ne...</td>\n",
       "      <td>my song  so glad  free download   shoegaze  ne...</td>\n",
       "      <td>my song  so glad  free download   shoegaze  ne...</td>\n",
       "      <td>my song  so glad  free download   shoegaze  ne...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "5          6    0.0  [2/2] huge fan fare and big talking before the...   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             clean_tweet  \\\n",
       "0      when a fatheare is dysfyounctional and is so s...   \n",
       "1      thanks foare #lyft careedit i cannot youse cay...   \n",
       "3      #model i love you take with you all the time i...   \n",
       "4             factsgareinyouide: society now #motivation   \n",
       "5      [2/2] hyougareine fan faaree and bigarein talk...   \n",
       "...                                                  ...   \n",
       "49154  thoyougareinht factoarey: left-areigareinht po...   \n",
       "49155  feelingarein like a mearemaid ð #haiareflip...   \n",
       "49156  #hillaarey #campaigareinned today in #ohio((oh...   \n",
       "49157  happy, at woarek confeareence: areigareinht mi...   \n",
       "49158  my songarein \"so gareinlad\" fareee download! #...   \n",
       "\n",
       "                                            clean_tweet1  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for #lyft credit i can't use cause they...   \n",
       "3      #model   i love u take with u all the time in ...   \n",
       "4                 factsguide: society now    #motivation   \n",
       "5      [2/2] huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory: left-right polarisation! #tru...   \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  happy, at work conference: right mindset leads...   \n",
       "49158  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                            clean_tweet3  bool  \\\n",
       "0      when a father is dysfunctional and is so selfi...  True   \n",
       "1      thanks for #lyft credit i cannot use cause the...  True   \n",
       "3      #model i love u take with u all the time in ur...  True   \n",
       "4                    factsguide: society now #motivation  True   \n",
       "5      [2/2] huge fan fare and big talking before the...  True   \n",
       "...                                                  ...   ...   \n",
       "49154  thought factory: left-right polarisation! #tru...  True   \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...  True   \n",
       "49156  #hillary #campaigned today in #ohio((omg)) &am...  True   \n",
       "49157  happy, at work conference: right mindset leads...  True   \n",
       "49158  my song \"so glad\" free download! #shoegaze #ne...  True   \n",
       "\n",
       "                                            clean_tweet4  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for #lyft credit i cannot use cause the...   \n",
       "3      #model i love you take with you all the time i...   \n",
       "4                    factsguide: society now #motivation   \n",
       "5      [2/2] huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory: left-right polarisation! #tru...   \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  happy, at work conference: right mindset leads...   \n",
       "49158  my song \"so glad\" free download! #shoegaze #ne...   \n",
       "\n",
       "                                            clean_tweet5  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for #lyft credit i cannot use cause the...   \n",
       "3      #model i love you take with you all the time i...   \n",
       "4                    factsguide: society now #motivation   \n",
       "5      [2/2] huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory: left-right polarisation! #tru...   \n",
       "49155  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  happy, at work conference: right mindset leads...   \n",
       "49158  my song \"so glad\" free download! #shoegaze #ne...   \n",
       "\n",
       "                                            clean_tweet6  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for  lyft credit i cannot use cause the...   \n",
       "3       model i love you take with you all the time i...   \n",
       "4                    factsguide  society now  motivation   \n",
       "5       2 2  huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory  left right polarisation   tru...   \n",
       "49155  feeling like a mermaid ð   hairflip  neverread...   \n",
       "49156   hillary  campaigned today in  ohio omg   amp ...   \n",
       "49157  happy  at work conference  right mindset leads...   \n",
       "49158  my song  so glad  free download   shoegaze  ne...   \n",
       "\n",
       "                                            clean_tweet7  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for  lyft credit i cannot use cause the...   \n",
       "3       model i love you take with you all the time i...   \n",
       "4                    factsguide  society now  motivation   \n",
       "5       2 2  huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory  left right polarisation   tru...   \n",
       "49155  feeling like a mermaid     hairflip  neverread...   \n",
       "49156   hillary  campaigned today in  ohio omg   amp ...   \n",
       "49157  happy  at work conference  right mindset leads...   \n",
       "49158  my song  so glad  free download   shoegaze  ne...   \n",
       "\n",
       "                                            clean_tweet8  \\\n",
       "0      when a father is dysfunctional and is so selfi...   \n",
       "1      thanks for  lyft credit i cannot use cause the...   \n",
       "3       model i love you take with you all the time i...   \n",
       "4                    factsguide  society now  motivation   \n",
       "5            huge fan fare and big talking before the...   \n",
       "...                                                  ...   \n",
       "49154  thought factory  left right polarisation   tru...   \n",
       "49155  feeling like a mermaid     hairflip  neverread...   \n",
       "49156   hillary  campaigned today in  ohio omg   amp ...   \n",
       "49157  happy  at work conference  right mindset leads...   \n",
       "49158  my song  so glad  free download   shoegaze  ne...   \n",
       "\n",
       "                                            clean_tweet9  \n",
       "0      when father is dysfunctional and is so selfish...  \n",
       "1      thanks for lyft credit cannot use cause they d...  \n",
       "3        model love you take with you all the time in ur  \n",
       "4                      factsguide society now motivation  \n",
       "5      huge fan fare and big talking before they leav...  \n",
       "...                                                  ...  \n",
       "49154  thought factory left right polarisation trump ...  \n",
       "49155  feeling like mermaid hairflip neverready forma...  \n",
       "49156  hillary campaigned today in ohio omg amp used ...  \n",
       "49157  happy at work conference right mindset leads t...  \n",
       "49158  my song so glad free download shoegaze newmusi...  \n",
       "\n",
       "[47600 rows x 13 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['bool'] = combine_df['clean_tweet8']!=combine_df['clean_tweet9']\n",
    "df = combine_df[combine_df['bool'] == True]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'      huge fan fare and big talking before they leave  chaos and pay disputes when they get there   allshowandnogo'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet8'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huge fan fare and big talking before they leave chaos and pay disputes when they get there allshowandnogo'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df['clean_tweet9'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk import tokenize as tknz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SR_Ad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SR_Ad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SR_Ad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['tweet_token'] = combine_df['clean_tweet9'].apply(lambda x: tknz.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_token'] = combine_df['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "combine_df['tweet_stemmed'] = combine_df['tweet_token'].apply(lambda x: [snowball.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_lemmatized'] = combine_df['tweet_token'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df = combine_df.drop(['clean_tweet','clean_tweet1','clean_tweet3','clean_tweet4','clean_tweet5','clean_tweet6',\n",
    "                             'clean_tweet7', 'clean_tweet8','bool'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['clean_tweet'] = combine_df['clean_tweet9'] \n",
    "combine_df = combine_df.drop(['clean_tweet9'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>[model, love, take, time, ur]</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>[factsguid, societi, motiv]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49154</th>\n",
       "      <td>49155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>[thought, factori, left, right, polaris, trump...</td>\n",
       "      <td>[thought, factory, left, right, polarisation, ...</td>\n",
       "      <td>thought factory left right polarisation trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49155</th>\n",
       "      <td>49156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverreadi, fo...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>49157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, amp, u...</td>\n",
       "      <td>[hillari, campaign, today, ohio, omg, amp, use...</td>\n",
       "      <td>[hillary, campaigned, today, ohio, omg, amp, u...</td>\n",
       "      <td>hillary campaigned today in ohio omg amp used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49157</th>\n",
       "      <td>49158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happi, work, confer, right, mindset, lead, cu...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>happy at work conference right mindset leads t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49158</th>\n",
       "      <td>49159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[song, glad, free, download, shoegaz, newmus, ...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>my song so glad free download shoegaze newmusi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1          2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3    0.0                                bihday your majesty   \n",
       "3          4    0.0  #model   i love u take with u all the time in ...   \n",
       "4          5    0.0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "49154  49155    NaN  thought factory: left-right polarisation! #tru...   \n",
       "49155  49156    NaN  feeling like a mermaid ð #hairflip #neverre...   \n",
       "49156  49157    NaN  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "49157  49158    NaN  happy, at work conference: right mindset leads...   \n",
       "49158  49159    NaN  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                          [model, love, take, time, ur]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, amp, u...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "0      [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1      [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                      [bihday, majesti]   \n",
       "3                          [model, love, take, time, ur]   \n",
       "4                            [factsguid, societi, motiv]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factori, left, right, polaris, trump...   \n",
       "49155  [feel, like, mermaid, hairflip, neverreadi, fo...   \n",
       "49156  [hillari, campaign, today, ohio, omg, amp, use...   \n",
       "49157  [happi, work, confer, right, mindset, lead, cu...   \n",
       "49158  [song, glad, free, download, shoegaz, newmus, ...   \n",
       "\n",
       "                                        tweet_lemmatized  \\\n",
       "0      [father, dysfunctional, selfish, drag, kid, dy...   \n",
       "1      [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                      [bihday, majesty]   \n",
       "3                          [model, love, take, time, ur]   \n",
       "4                      [factsguide, society, motivation]   \n",
       "...                                                  ...   \n",
       "49154  [thought, factory, left, right, polarisation, ...   \n",
       "49155  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "49156  [hillary, campaigned, today, ohio, omg, amp, u...   \n",
       "49157  [happy, work, conference, right, mindset, lead...   \n",
       "49158  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                             clean_tweet  \n",
       "0      when father is dysfunctional and is so selfish...  \n",
       "1      thanks for lyft credit cannot use cause they d...  \n",
       "2                                    bihday your majesty  \n",
       "3        model love you take with you all the time in ur  \n",
       "4                      factsguide society now motivation  \n",
       "...                                                  ...  \n",
       "49154  thought factory left right polarisation trump ...  \n",
       "49155  feeling like mermaid hairflip neverready forma...  \n",
       "49156  hillary campaigned today in ohio omg amp used ...  \n",
       "49157  happy at work conference right mindset leads t...  \n",
       "49158  my song so glad free download shoegaze newmusi...  \n",
       "\n",
       "[49159 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                49159 non-null  int64  \n",
      " 1   label             31962 non-null  float64\n",
      " 2   tweet             49159 non-null  object \n",
      " 3   tweet_token       49159 non-null  object \n",
      " 4   tweet_stemmed     49159 non-null  object \n",
      " 5   tweet_lemmatized  49159 non-null  object \n",
      " 6   clean_tweet       49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "combine_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "combine_df.to_pickle(\"resHW01.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
